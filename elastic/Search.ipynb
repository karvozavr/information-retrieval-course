{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import requests\n",
    "from time import time\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'queries_xml': '/home/subject/Downloads/web2008_adhoc.xml', # path to queries xml\n",
    "    'relevance_xml': '/home/subject/Downloads/or_relevant-minus_table.xml', # path to relevance xml\n",
    "    'collection_dir': '/home/subject/Documents/informational retrieval/all_info2/', # folder with contents of all_info.zip\n",
    "    'pagerank_json' : '/home/subject/Documents/informational retrieval/pagerank.json' # json file with pageranks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'timeout': 360, 'maxsize': 25}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not es.indices.exists(index='byweb'):\n",
    "    es.indices.create(index='byweb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'content': {\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'stem_content': {\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'title': {\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'id': {\n",
    "                'type': 'keyword'\n",
    "            },\n",
    "            'url': {\n",
    "                'type': 'keyword'\n",
    "            },\n",
    "            'pagerank': {\n",
    "                'type': 'rank_feature'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'settings': {\n",
    "       'analysis': {\n",
    "            'analyzer': {\n",
    "                'white_lover': {\n",
    "                    'tokenizer': 'white_20',\n",
    "                    'filter': [\n",
    "                        'lowercase'\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            'tokenizer': {\n",
    "                'white_20': {\n",
    "                    'type': 'whitespace'\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_index():\n",
    "    es.indices.delete(index='byweb')\n",
    "    es.indices.create(index='byweb', body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 1 µs, total: 8 µs\n",
      "Wall time: 16.9 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "recreate_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval of pagerank\n",
    "def get_rank_jsons():\n",
    "    file = settings['pagerank_json']\n",
    "    with open(file) as f:\n",
    "        l = json.load(f)\n",
    "        return dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank_dict = get_rank_jsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "def get_pagerank_by_url(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    # lonely vertex -> pagerank is small\n",
    "    return pagerank_dict.get(domain, 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_source': document\n",
    "    }\n",
    "\n",
    "def es_actions_generator(docs):\n",
    "    for doc in os.listdir(docs):\n",
    "        doc = os.path.join(docs, doc)\n",
    "        with open(doc) as d:\n",
    "            data = json.load(d)\n",
    "            for document in data:\n",
    "                document['pagerank'] = get_pagerank_by_url(document[\"url\"])\n",
    "                yield create_es_action('byweb', document['id'], document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcb0b619ca44755b3fdba8149965c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generator = es_actions_generator(settings['collection_dir'])\n",
    "for ok, result in tqdm(parallel_bulk(es, generator, queue_size=4, thread_count=4, chunk_size=1000)):\n",
    "    if not ok:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время работы процедуры выше: ~5 минут.\n",
    "\n",
    "Если посмотрим сюда: \"http://localhost:9200/_stats/indexing,store?pretty \" и найдем:\n",
    "\n",
    "`indices.byweb.total.store.size_in_bytes`\n",
    "\n",
    "увидим, что размер индекса равен ~3 Гб. Размер информации, запихнутой в индекс, ~4.1 Гб. \n",
    "\n",
    "Размер индекса с Pagerank - ~4 Гб.\n",
    "\n",
    "(Конечно, все это можно было сделать программно, но посмотреть на один показатель быстрее ручками.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query = namedtuple('Query', ['query_id', 'text', 'relevant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(query):\n",
    "    text = query.find('{http://www.romip.ru/data/adhoc}querytext').text\n",
    "    query_id = query.attrib['id']\n",
    "    return Query(query_id=query_id, text=text, relevant=[])\n",
    "\n",
    "\n",
    "def extract_queries():\n",
    "    filename = settings['queries_xml']\n",
    "    with open(filename) as f:\n",
    "        tree = ET.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        tasks = root.findall('{http://www.romip.ru/data/adhoc}task')\n",
    "        qs = list(map(parse_query, tasks))\n",
    "        queries = dict()\n",
    "        for x in qs:\n",
    "            queries[x.query_id] = x\n",
    "        return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevance():\n",
    "    queries_dict = extract_queries()\n",
    "    def parse_relevance(query):\n",
    "        query_id = query.attrib['id']\n",
    "        q = queries_dict[query_id]\n",
    "        for doc in query.findall('./{http://www.romip.ru/common/merged-results}document'):\n",
    "            if doc.attrib['relevance'] == 'vital':\n",
    "                q.relevant.append(doc.attrib['id'])\n",
    "        return q\n",
    "\n",
    "    filename = settings['relevance_xml']\n",
    "    with open(filename) as f:\n",
    "        tree = ET.parse(filename)\n",
    "        root = tree.getroot()\n",
    "        tasks = root.findall('{http://www.romip.ru/common/merged-results}task')\n",
    "        return list(map(parse_relevance, tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n"
     ]
    }
   ],
   "source": [
    "queries = extract_relevance()\n",
    "# important: -38 queries\n",
    "queries = list(filter(lambda q: q.relevant, queries))\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, result_size=20):\n",
    "    \"\"\"\n",
    "    Use this function for search.\n",
    "    \"\"\"\n",
    "    \n",
    "    query = {\n",
    "        'query': {\n",
    "             'bool': {\n",
    "                'should': \n",
    "                    {\n",
    "                        'match': {\n",
    "                            'content': query.text.lower()\n",
    "                        }\n",
    "                    }\n",
    "             }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    result = es.search(index='byweb', body=query, size=result_size)\n",
    "    return list(map(lambda x: x['_id'], result['hits']['hits']))\n",
    "\n",
    "def pretty_print_result(search_result):\n",
    "    res = search_result['hits']\n",
    "    print(f'Total documents: {res[\"total\"][\"value\"]}')\n",
    "    for hit in res['hits']:\n",
    "        print(f'Doc {hit[\"_id\"]}, score is {hit[\"_score\"]}')\n",
    "                  \n",
    "def get_doc_by_id(doc_id):\n",
    "    return es.get(index='byweb', id=doc_id)['_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статистические показатели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns [precision, recall, recall-]. Last one is for educational purpose only.\n",
    "def stats_at(k, query, query_result):\n",
    "    relevant = query.relevant\n",
    "    result_at_k = query_result[:k]\n",
    "\n",
    "    good = set(result_at_k).intersection(relevant)\n",
    "    return [len(good) / k, len(good) / len(relevant), len(good) / min(k, len(relevant))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns [ap, ap-r, ap-k, ap-]. Last 3 are for educational purpose only\n",
    "def get_ap_at(k, query, query_result):\n",
    "    s = 0\n",
    "    n = 0\n",
    "    relevant = query.relevant\n",
    "    result_at_k = query_result[:k]\n",
    "\n",
    "    for i in range(len(result_at_k)):\n",
    "        result = result_at_k[i]\n",
    "        if result in relevant:\n",
    "            s += stats_at(i + 1, query, result_at_k)[0]\n",
    "            n += 1\n",
    "    \n",
    "    return [s / n if n != 0 else 0, s / len(relevant), s / k, s / min(k, len(relevant))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns [map, map-r, map-k, map-]. Last 3 are for educational purpose only\n",
    "def get_map_at(k, queries, q_results):\n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    s3 = 0\n",
    "    s4 = 0\n",
    "    for query, query_result in zip(queries, q_results):\n",
    "        ap = get_ap_at(k, query, query_result)\n",
    "        s1 += ap[0]\n",
    "        s2 += ap[1]\n",
    "        s3 += ap[2]\n",
    "        s4 += ap[3]\n",
    "    return [s1 / len(queries), s2 / len(queries), s3 / len(queries), s4 / len(queries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries_results(qs, search_fun=search, k=20):\n",
    "    # important: k = max(k, len(q.relevant)), because for r-precision we may need more than k.\n",
    "    return [search_fun(q, max(k, len(q.relevant))) for q in qs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries_stats(search_fun, k=20):\n",
    "    results = get_queries_results(queries, search_fun, k)\n",
    "    \n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    recall_dash = 0\n",
    "    r_precision = 0\n",
    "    for q, r in zip(queries, results):\n",
    "        stats = stats_at(k, q, r)\n",
    "        precision += stats[0]\n",
    "        recall += stats[1]\n",
    "        recall_dash += stats[2]\n",
    "        r_precision += stats_at(len(q.relevant), q, r)[0]\n",
    "    \n",
    "    queries_size = len(queries)\n",
    "    print(\"Средняя точность на уровне k=20 по всем запросам:\", precision / queries_size)\n",
    "    print(\"Средняя полнота на уровне k=20 по всем запросам:\", recall / queries_size)\n",
    "    print(\"Средняя полнота-дэш (в знаментеле стоит k, если релевантных документов больше, чем k) на уровне k=20 по всем запросам:\", recall_dash / queries_size)\n",
    "    print(\"Средняя R-точность по всем запросам:\", r_precision / queries_size)\n",
    "    map_at = get_map_at(k, queries, results)\n",
    "    print(\"MAP на уровне k=20:\", map_at[0])\n",
    "    print(\"MAP-r (в знаменателе AP - количество всех релевантных документов для запроса) на уровне k=20:\", map_at[1])\n",
    "    print(\"MAP-k (в знаменателе AP - k) на уровне k=20:\", map_at[2])\n",
    "    print(\"MAP-дэш (в знаменателе AP - k, если релевантных документов больше k, иначе - количество всех релевантных документов для запроса) на уровне k=20:\", map_at[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность на уровне k=20 по всем запросам: 0.33878787878787886\n",
      "Средняя полнота на уровне k=20 по всем запросам: 0.22243745709461563\n",
      "Средняя полнота-дэш (в знаментеле стоит k, если релевантных документов больше, чем k) на уровне k=20 по всем запросам: 0.39414125273704026\n",
      "Средняя R-точность по всем запросам: 0.27752064450795616\n",
      "MAP на уровне k=20: 0.505302904265171\n",
      "MAP-r (в знаменателе AP - количество всех релевантных документов для запроса) на уровне k=20: 0.15013623269259188\n",
      "MAP-k (в знаменателе AP - k) на уровне k=20: 0.26675960103013524\n",
      "MAP-дэш (в знаменателе AP - k, если релевантных документов больше k, иначе - количество всех релевантных документов для запроса) на уровне k=20: 0.2939187654754581\n"
     ]
    }
   ],
   "source": [
    "get_queries_stats(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loops, best of 3: 5.31 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "_ = get_queries_results(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметки:\n",
    "\n",
    "Query(query_id='arw53730', text='Ремолан', relevant=['980017']) []\n",
    "потому что mystem, ремолать?\n",
    "\n",
    "Зачем нужны дэш-характеристики:\n",
    "\n",
    "Query(query_id='arw50384', text='гизметео', relevant=['587130', '856298', '239338', '239387', '239377', '687059', '261338', '325277', '72835', '1285231', '223037', '1382550', '37733', '92274', '92282', '1420731', '689932', '1303050', '963503', '602944', '1372162', '256386', '1427662', '1464330', '1357789']) ['1420731', '691030'] 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка для лемматизации запроса; совпадает с лемматизацией для коллекции.\n",
    "\n",
    "stop_words = {'г', '©'}\n",
    "def get_stop_words(files):\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            for word in f:\n",
    "                stop_words.add(word.split()[0])\n",
    "\n",
    "get_stop_words(['../extractor/stopwords/english', '../extractor/stopwords/russian'])\n",
    "\n",
    "def is_not_stop_word(d):\n",
    "    return not getLexOrText(d) in stop_words\n",
    "\n",
    "\n",
    "normal_word = re.compile('^[A-Za-z0-9Ѐ-ӿ]*$')\n",
    "def is_normal_word(d):\n",
    "    return normal_word.match(d['text']) is not None\n",
    "\n",
    "\n",
    "def getText(d):\n",
    "    return d['text'].lower()\n",
    "\n",
    "def getLexOrText(d):\n",
    "    if 'analysis' not in d or not d['analysis']:\n",
    "        return getText(d)\n",
    " \n",
    "    analysis = d['analysis'][0]\n",
    "    return analysis['lex'] if 'lex' in analysis else getText(d)\n",
    "\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "\n",
    "def lemmatize(query_text):\n",
    "    result = m.analyze(query_text)\n",
    "\n",
    "    result = list(filter(bool, result))\n",
    "    result = list(filter(lambda x: 'analysis' in x or is_normal_word(x), result))\n",
    "    json_results = list(filter(is_not_stop_word, result))\n",
    "\n",
    "    lexed_content = \" \".join(list(map(getLexOrText, json_results)))\n",
    "    return lexed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_search(query, result_size=20):\n",
    "    query_text = lemmatize(query.text)\n",
    "    query = {\n",
    "        'query': {\n",
    "             'bool': {\n",
    "                'should': \n",
    "                    {\n",
    "                        'match': {\n",
    "                            'stem_content': query_text\n",
    "                        }\n",
    "                    }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index='byweb', body=query, size=result_size)\n",
    "    return list(map(lambda x: x['_id'], result['hits']['hits']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность на уровне k=20 по всем запросам: 0.39818181818181864\n",
      "Средняя полнота на уровне k=20 по всем запросам: 0.2712074457516083\n",
      "Средняя полнота-дэш (в знаментеле стоит k, если релевантных документов больше, чем k) на уровне k=20 по всем запросам: 0.46816114139549775\n",
      "Средняя R-точность по всем запросам: 0.33883150733062384\n",
      "MAP на уровне k=20: 0.5535287107311269\n",
      "MAP-r (в знаменателе AP - количество всех релевантных документов для запроса) на уровне k=20: 0.1856681552625555\n",
      "MAP-k (в знаменателе AP - k) на уровне k=20: 0.3158996055921541\n",
      "MAP-дэш (в знаменателе AP - k, если релевантных документов больше k, иначе - количество всех релевантных документов для запроса) на уровне k=20: 0.3534022369404635\n"
     ]
    }
   ],
   "source": [
    "get_queries_stats(l_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loops, best of 3: 5.51 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "_ = get_queries_results(queries, l_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_search(query, result_size=20, saturation={}):\n",
    "    query_text = lemmatize(query.text)\n",
    "    query = {\n",
    "        'query': {\n",
    "             'bool': {\n",
    "                'should': [\n",
    "                    {\n",
    "                        'match': {\n",
    "                            'stem_content': {\n",
    "                                'query': query_text,\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        'rank_feature': {\n",
    "                            'field': 'pagerank',\n",
    "                            'saturation': saturation,\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    result = es.search(index='byweb', body=query, size=result_size)\n",
    "    return list(map(lambda x: x['_id'], result['hits']['hits']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность на уровне k=20 по всем запросам: 0.3941414141414144\n",
      "Средняя полнота на уровне k=20 по всем запросам: 0.27245669655357124\n",
      "Средняя полнота-дэш (в знаментеле стоит k, если релевантных документов больше, чем k) на уровне k=20 по всем запросам: 0.4660861082987928\n",
      "Средняя R-точность по всем запросам: 0.33465876874214934\n",
      "MAP на уровне k=20: 0.5476735995697807\n",
      "MAP-r (в знаменателе AP - количество всех релевантных документов для запроса) на уровне k=20: 0.18252628043917526\n",
      "MAP-k (в знаменателе AP - k) на уровне k=20: 0.3105606037092688\n",
      "MAP-дэш (в знаменателе AP - k, если релевантных документов больше k, иначе - количество всех релевантных документов для запроса) на уровне k=20: 0.3463676750901122\n"
     ]
    }
   ],
   "source": [
    "get_queries_stats(lp_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность на уровне k=20 по всем запросам: 0.39848484848484883\n",
      "Средняя полнота на уровне k=20 по всем запросам: 0.2718922305790838\n",
      "Средняя полнота-дэш (в знаментеле стоит k, если релевантных документов больше, чем k) на уровне k=20 по всем запросам: 0.46903124594981277\n",
      "Средняя R-точность по всем запросам: 0.33831016924139967\n",
      "MAP на уровне k=20: 0.5513408942425277\n",
      "MAP-r (в знаменателе AP - количество всех релевантных документов для запроса) на уровне k=20: 0.1854266741485779\n",
      "MAP-k (в знаменателе AP - k) на уровне k=20: 0.31559249897822916\n",
      "MAP-дэш (в знаменателе AP - k, если релевантных документов больше k, иначе - количество всех релевантных документов для запроса) на уровне k=20: 0.353160124055841\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "saturation = {'pivot': 1e-6}\n",
    "get_queries_stats(partial(lp_search, saturation=saturation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность на уровне k=20 по всем запросам: 0.3984848484848489\n",
      "Средняя полнота на уровне k=20 по всем запросам: 0.2719752747075097\n",
      "Средняя полнота-дэш (в знаментеле стоит k, если релевантных документов больше, чем k) на уровне k=20 по всем запросам: 0.4690564984750653\n",
      "Средняя R-точность по всем запросам: 0.3386345237853433\n",
      "MAP на уровне k=20: 0.5529794553779379\n",
      "MAP-r (в знаменателе AP - количество всех релевантных документов для запроса) на уровне k=20: 0.18566011409832686\n",
      "MAP-k (в знаменателе AP - k) на уровне k=20: 0.31604154047420285\n",
      "MAP-дэш (в знаменателе AP - k, если релевантных документов больше k, иначе - количество всех релевантных документов для запроса) на уровне k=20: 0.3536093762169382\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "saturation = {'pivot': 1e-8}\n",
    "get_queries_stats(partial(lp_search, saturation=saturation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loops, best of 3: 6.84 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "_ = get_queries_results(queries, lp_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pagerank слегка ухудшил результат. Заметим, что если поиграться с pivot, можно добиться небольшого улучшения даже относительно l_search, но ничего значительного не получим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lt_search(query, result_size=20):\n",
    "    query_text = lemmatize(query.text)\n",
    "    query = {\n",
    "        'query': {\n",
    "             'bool': {\n",
    "                'should': [\n",
    "                    {\n",
    "                        'match': {\n",
    "                            'stem_content': {\n",
    "                                'query': query_text,\n",
    "                                'boost': 10\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        'match': {\n",
    "                            'title': {\n",
    "                                'query': query.text\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    result = es.search(index='byweb', body=query, size=result_size)\n",
    "    return list(map(lambda x: x['_id'], result['hits']['hits']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность на уровне k=20 по всем запросам: 0.4075757575757578\n",
      "Средняя полнота на уровне k=20 по всем запросам: 0.27798909725396764\n",
      "Средняя полнота-дэш (в знаментеле стоит k, если релевантных документов больше, чем k) на уровне k=20 по всем запросам: 0.4801656277549889\n",
      "Средняя R-точность по всем запросам: 0.35278865631007517\n",
      "MAP на уровне k=20: 0.5680905712742932\n",
      "MAP-r (в знаменателе AP - количество всех релевантных документов для запроса) на уровне k=20: 0.19083621687895494\n",
      "MAP-k (в знаменателе AP - k) на уровне k=20: 0.3251037497682118\n",
      "MAP-дэш (в знаменателе AP - k, если релевантных документов больше k, иначе - количество всех релевантных документов для запроса) на уровне k=20: 0.36461177147359297\n"
     ]
    }
   ],
   "source": [
    "get_queries_stats(lt_search) # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loops, best of 3: 6.35 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3 -r 3\n",
    "_ = get_queries_results(queries, lt_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
